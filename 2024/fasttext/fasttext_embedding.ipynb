{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987f861c",
   "metadata": {},
   "source": [
    "<b> Code example of using the Fasttext library. For more details consult the documentaion </b> https://fasttext.cc/docs/en/support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8409b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pprint\n",
    "import inspect\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc4ab7",
   "metadata": {},
   "source": [
    "<b> Fasttext.train_supervised takes txt file as input and has good default arguments. you can change the paramenters as you see in the example. The output is a model object which can produce word vector and get neighbor words.\n",
    "Check out supervised training of fasttext</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3643e8f-a5c5-4a91-8bb5-b5c62a3a90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text files combined into combined_training_data.txt\n"
     ]
    }
   ],
   "source": [
    "# Directory containing your text files\n",
    "data_dir = 'data_2'\n",
    "\n",
    "# Output file to store the combined data\n",
    "output_file = 'combined_training_data.txt'\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.txt'):  # Only process .txt files\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                # Write content of each file into the output file\n",
    "                outfile.write(infile.read() + \"\\n\")\n",
    "\n",
    "print(f\"All text files combined into {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42d2519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 450M words\n",
      "Number of words:  996767\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   32813 lr:  0.000000 avg.loss:  0.508162 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# training is very simple and on high level. We try with the default settings\n",
    "model = fasttext.train_unsupervised('combined_training_data.txt', model='skipgram', dim=200)\n",
    "#playing with the parameters\n",
    "#model = fasttext.train_unsupervised('data/training_data.txt', model='skipgram', \n",
    "#                                    minn=2, maxn=5, dim=300, epoch=1, lr=0.5, thread=4)\n",
    "# default values (\"dim=100\": controls the number of dimensions of a vector) \"100-300 range is popular\"\n",
    "#                 (\"minn=2\": The subwords are all the substrings contained in a word between the minimum size \n",
    "#                  (minn) and the maximal size (maxn).) default between 3 and 6\n",
    "#                  (epoch=1: default 5)\n",
    "#                   (lr=0.5: default value is 0.05) \"the faster the model converge to a solution \n",
    "#                    but at the risk of overfitting to the dataset\"\n",
    "#                   (\"thread=4\" default=12) fastText is multi-threaded and uses 12 threads by default. \n",
    "#                    If you have less CPU cores (say 4), you can easily set the number of threads using the thread flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7a821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bucket',\n",
      " 'dim',\n",
      " 'epoch',\n",
      " 'f',\n",
      " 'get_analogies',\n",
      " 'get_dimension',\n",
      " 'get_input_matrix',\n",
      " 'get_input_vector',\n",
      " 'get_label_id',\n",
      " 'get_labels',\n",
      " 'get_line',\n",
      " 'get_meter',\n",
      " 'get_nearest_neighbors',\n",
      " 'get_output_matrix',\n",
      " 'get_sentence_vector',\n",
      " 'get_subword_id',\n",
      " 'get_subwords',\n",
      " 'get_word_id',\n",
      " 'get_word_vector',\n",
      " 'get_words',\n",
      " 'is_quantized',\n",
      " 'label',\n",
      " 'labels',\n",
      " 'loss',\n",
      " 'lr',\n",
      " 'lrUpdateRate',\n",
      " 'maxn',\n",
      " 'minCount',\n",
      " 'minCountLabel',\n",
      " 'minn',\n",
      " 'neg',\n",
      " 'predict',\n",
      " 'pretrainedVectors',\n",
      " 'quantize',\n",
      " 'save_model',\n",
      " 'set_args',\n",
      " 'set_matrices',\n",
      " 't',\n",
      " 'test',\n",
      " 'test_label',\n",
      " 'thread',\n",
      " 'verbose',\n",
      " 'wordNgrams',\n",
      " 'words',\n",
      " 'ws']\n"
     ]
    }
   ],
   "source": [
    "# let's find out what we can do with the model object [what methods and attributes it has]\n",
    "methods_attr = [item for item in dir(model) if not item.startswith(\"_\")]\n",
    "pprint.pprint(methods_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c3f98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Methods: ['get_analogies', 'get_dimension', 'get_input_matrix', \"\n",
      " \"'get_input_vector', 'get_label_id', 'get_labels', 'get_line', 'get_meter', \"\n",
      " \"'get_nearest_neighbors', 'get_output_matrix', 'get_sentence_vector', \"\n",
      " \"'get_subword_id', 'get_subwords', 'get_word_id', 'get_word_vector', \"\n",
      " \"'get_words', 'is_quantized', 'predict', 'quantize', 'save_model', \"\n",
      " \"'set_args', 'set_matrices', 'test', 'test_label']\")\n",
      "(\"Attributes: ['bucket', 'dim', 'epoch', 'f', 'label', 'labels', 'loss', 'lr', \"\n",
      " \"'lrUpdateRate', 'maxn', 'minCount', 'minCountLabel', 'minn', 'neg', \"\n",
      " \"'pretrainedVectors', 't', 'thread', 'verbose', 'wordNgrams', 'words', 'ws']\")\n"
     ]
    }
   ],
   "source": [
    "# Separate methods and attributes\n",
    "methods = [item for item in methods_attr if inspect.ismethod(getattr(model, item))]\n",
    "attributes = [item for item in methods_attr if not inspect.ismethod(getattr(model, item))]\n",
    "\n",
    "# Pretty print the methods and attributes\n",
    "pprint.pprint(f\"Methods: {methods}\")\n",
    "pprint.pprint(f\"Attributes: {attributes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08da27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(wordA, wordB, wordC, k=10, on_unicode_error='strict')\n",
      "(word, on_unicode_error='strict')\n"
     ]
    }
   ],
   "source": [
    "# let's get info on the arguments of some of the methods\n",
    "print(inspect.signature(model.get_dimension))\n",
    "print(inspect.signature(model.get_analogies))\n",
    "print(inspect.signature(model.get_subwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11ec7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.62398893e-01,  8.12202916e-02, -2.67764688e-01, -7.68128037e-02,\n",
       "        1.57742396e-01, -1.13313183e-01,  1.52611107e-01,  4.86544907e-01,\n",
       "       -2.40758568e-01, -4.08467144e-01,  7.24291280e-02, -2.09741294e-01,\n",
       "        1.19522475e-01, -3.60782683e-01, -3.87418061e-01,  1.45134017e-01,\n",
       "        4.32168096e-01, -1.11449845e-01,  3.60231032e-03, -1.00929327e-01,\n",
       "        3.43433142e-01, -1.22957811e-01,  2.84534067e-01,  4.78930622e-01,\n",
       "        2.55102187e-01,  3.03595923e-02, -6.45152181e-02, -1.30704701e-01,\n",
       "        1.27844587e-01,  3.29458326e-01,  1.25470012e-01, -4.78381440e-02,\n",
       "       -3.62820864e-01, -3.10503423e-01, -2.59261847e-01, -2.33823508e-01,\n",
       "        1.03295691e-01, -2.26096004e-01,  2.47430429e-01,  3.84607971e-01,\n",
       "       -1.59989163e-01,  1.24242231e-02, -5.98286450e-01, -2.87795991e-01,\n",
       "       -4.01901960e-01, -1.28270537e-01, -3.98319475e-02,  6.53634012e-01,\n",
       "       -1.91364170e-03, -3.09041934e-03, -9.84952450e-02,  1.21091910e-01,\n",
       "       -3.34523976e-01,  2.60441422e-01,  6.77848458e-02,  4.84029531e-01,\n",
       "       -1.08888812e-01,  1.23661280e-01,  1.92244560e-01,  5.18710613e-02,\n",
       "       -4.15011853e-01, -2.32160777e-01, -3.20065588e-01, -1.83870494e-01,\n",
       "        4.93537009e-01, -2.86029369e-01, -3.20390612e-01,  2.36742813e-02,\n",
       "       -2.47494243e-02, -4.86827455e-02, -3.73091340e-01,  1.99619114e-01,\n",
       "       -2.40002289e-01,  3.17803919e-01, -1.55601189e-01, -1.05111994e-01,\n",
       "       -1.06081076e-01,  1.09670766e-01, -2.27160498e-01,  9.38982293e-02,\n",
       "       -1.03277378e-02, -1.57831639e-01, -3.44153017e-01,  5.94835758e-01,\n",
       "       -9.82305873e-03, -5.31707704e-02, -9.49408561e-02, -2.96958983e-01,\n",
       "       -1.96435124e-01,  2.33095169e-01, -1.18938550e-01, -5.31248935e-02,\n",
       "        1.10693440e-01,  5.13313651e-01,  6.88344315e-02,  3.39474808e-03,\n",
       "       -1.07681729e-01, -3.37655395e-01, -8.55868384e-02, -2.04366386e-01,\n",
       "       -2.05649465e-01,  2.45074406e-01, -1.18782848e-01, -3.92330527e-01,\n",
       "        5.21640517e-02,  3.33730549e-01, -1.66986749e-01, -1.26473576e-01,\n",
       "        1.31752923e-01,  6.26130819e-01,  1.91285238e-02, -8.02851617e-01,\n",
       "        1.07539959e-01, -5.29358573e-02, -4.84823167e-01, -1.51073128e-01,\n",
       "       -7.74027556e-02, -2.46398076e-01, -2.41952375e-01, -1.49471879e-01,\n",
       "       -1.10695958e-02, -5.55610918e-02, -4.28135917e-02,  4.59543504e-02,\n",
       "        8.86891782e-02, -3.78376693e-01,  2.69755274e-01,  3.35830063e-01,\n",
       "        2.51917616e-02,  3.53862256e-01,  2.55517185e-01, -4.94937509e-01,\n",
       "       -6.18540168e-01,  1.18182659e-01,  2.23843858e-01,  3.45391408e-02,\n",
       "       -5.40134311e-01, -2.70716250e-01, -1.94481462e-01,  3.91892821e-01,\n",
       "       -2.89962478e-02,  1.44235536e-01, -1.13965675e-01,  1.40709765e-02,\n",
       "       -1.98155001e-01, -1.19629658e-04,  1.74527958e-01, -1.48670584e-01,\n",
       "        1.86993927e-01, -1.55838847e-01,  8.64531472e-03, -6.83881044e-02,\n",
       "        8.14570263e-02, -1.96473882e-01, -3.28863710e-01, -3.24901342e-01,\n",
       "       -9.94454473e-02,  4.45146829e-01, -7.25810587e-01, -5.55060245e-03,\n",
       "       -3.35727125e-01,  6.95822611e-02, -7.93786428e-04,  2.62233734e-01,\n",
       "       -3.73562664e-01,  1.30309120e-01,  4.91966084e-02, -1.20492883e-01,\n",
       "       -1.46517083e-01,  1.10425897e-01, -6.44376650e-02, -3.81476700e-01,\n",
       "       -1.23869441e-01, -3.02253634e-01, -1.10954614e-02,  2.85331458e-01,\n",
       "       -1.08376957e-01, -9.02279094e-02,  2.72211641e-01, -2.41896436e-01,\n",
       "       -1.00596316e-01,  5.58416605e-01,  2.78632522e-01,  2.14736965e-02,\n",
       "       -1.05087675e-01,  1.04560636e-01,  1.74026303e-02,  3.59879136e-01,\n",
       "       -2.92037427e-01, -6.84821546e-01, -4.15704280e-01,  2.38270253e-01,\n",
       "       -2.98835516e-01, -1.95801213e-01,  7.66567513e-02, -1.33196592e-01,\n",
       "       -2.87682176e-01,  9.33049247e-03, -4.81910914e-01, -8.92559960e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_word_vector(\"father\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda9a9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8769745230674744, 'schoolteacher'),\n",
       " (0.8637434840202332, 'teacher,'),\n",
       " (0.8260265588760376, 'schoolteacher,'),\n",
       " (0.8106196522712708, 'pupil-teacher'),\n",
       " (0.8057887554168701, 'teacher.'),\n",
       " (0.799347996711731, 'teacher;'),\n",
       " (0.7882447242736816, 'teacher\"'),\n",
       " (0.7877546548843384, 'teacher:'),\n",
       " (0.7810304164886475, 'teacher)'),\n",
       " (0.7784423232078552, 'schoolteacher.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_nearest_neighbors(\"teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bd6935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['university',\n",
       "  '<un',\n",
       "  '<uni',\n",
       "  '<univ',\n",
       "  '<unive',\n",
       "  'uni',\n",
       "  'univ',\n",
       "  'unive',\n",
       "  'univer',\n",
       "  'niv',\n",
       "  'nive',\n",
       "  'niver',\n",
       "  'nivers',\n",
       "  'ive',\n",
       "  'iver',\n",
       "  'ivers',\n",
       "  'iversi',\n",
       "  'ver',\n",
       "  'vers',\n",
       "  'versi',\n",
       "  'versit',\n",
       "  'ers',\n",
       "  'ersi',\n",
       "  'ersit',\n",
       "  'ersity',\n",
       "  'rsi',\n",
       "  'rsit',\n",
       "  'rsity',\n",
       "  'rsity>',\n",
       "  'sit',\n",
       "  'sity',\n",
       "  'sity>',\n",
       "  'ity',\n",
       "  'ity>',\n",
       "  'ty>'],\n",
       " array([  10637, 2006539, 1369982, 2221226, 2277193, 2330984, 2734796,\n",
       "        2460663, 2611517, 2064761, 2896076, 2752556, 2348153, 2161736,\n",
       "        2493280, 1624789, 2268716, 1207329, 2911362, 2990173, 2760605,\n",
       "        1639134, 2861953, 1927873, 2686432, 2186816, 2464494, 1913761,\n",
       "        1832339, 2031614, 1754993, 1826723, 1425642, 1717838, 1060559]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_subwords(\"university\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f650b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8165403604507446, 'â€œdaughter'),\n",
       " (0.8020674586296082, 'daughter,'),\n",
       " (0.799014151096344, 'goddaughter')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"father\", \"mother\", \"daughter\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c22379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7275875806808472, 'Paris'),\n",
       " (0.7073453664779663, 'Berlin_'),\n",
       " (0.6804660558700562, 'Francfort'),\n",
       " (0.6751400232315063, 'Berline')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_analogies(\"Berlin\", \"Germany\", \"France\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dacb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save_model(\"embedding_9m_word.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2799ee",
   "metadata": {},
   "source": [
    "<b> let's try a pretrained model that is much larger.\n",
    "Please note that it might not load on your memory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c8a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download pretrained model\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fdb7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#fasttext.util.download_model('en', if_exists='ignore')\n",
    "lg_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model.get_nearest_neighbors('father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29408651",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model.get_analogies(\"Berlin\", \"Germany\", \"France\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model.get_analogies(\"father\", \"mother\", \"daughter\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31a426-1a1a-4517-ab1d-594abdb90e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model.get_nearest_neighbors('color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f680f0de-bd9a-40c4-af46-9c078f25aca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7013290524482727, 'gynecologist'),\n",
       " (0.6668133735656738, 'physician'),\n",
       " (0.6592792272567749, 'gynocologist'),\n",
       " (0.6535542011260986, 'gynaecologist'),\n",
       " (0.6520789861679077, 'OBGYN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model.get_analogies(\"doctor\", \"man\", \"woman\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa542a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91aae0",
   "metadata": {},
   "source": [
    "<b> Let's try to use the model we trained instead of the tf-idf we used previously with the random forest classifier </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff71a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeda2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the JSON file\n",
    "with open('train_data.json', 'r') as file:\n",
    "    data = pd.read_json(file)\n",
    "\n",
    "# Use only 4400 examples (4000 for training and 400 for testing)\n",
    "data = data.sample(4400, random_state=42)\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65406689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=400, random_state=42)\n",
    "\n",
    "# Load the FastText model\n",
    "model = fasttext.load_model(\"embedding_1m_word.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize text using FastText\n",
    "def vectorize_text(texts):\n",
    "    vectorized_texts = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_vectors = [model.get_word_vector(word) for word in words]\n",
    "        text_vector = np.mean(word_vectors, axis=0)\n",
    "        vectorized_texts.append(text_vector)\n",
    "    return np.vstack(vectorized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the training and testing text data\n",
    "X_train_vec = vectorize_text(X_train)\n",
    "X_test_vec = vectorize_text(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef9c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7fe14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
