{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8b55f6-3a73-42f6-b452-8728d876558e",
   "metadata": {},
   "source": [
    "<b> Notebook to use pytorch for creating a simple feedforward netowrk and train it on dataset for binary classification for spam detection of sms. The data is available on the following link: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset/data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb019010-2678-450f-bbc3-5b47a84d7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "# Download necessary NLTK resources (for tokenization)\n",
    "#nltk.download('punkt')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ac63f-0ef7-4d04-a04b-15814082db67",
   "metadata": {},
   "source": [
    "<b> SECTION 1: first we open the dataset file and explore the data to have better understanding of it</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31324ea8-4ade-4ee4-b0b1-0a282166b478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "# Since there is a Unicode error in the dataset, we use the encoding 'latin-1' to handle the text properly\n",
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "\n",
    "# Step 2: Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47309158-6d3f-4533-aeb8-529b9bceda96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the column names to understand the structure of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec95ee2-b708-43ca-b23a-7ea13046d4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham', 'spam'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[\"v1\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f64d0b0-25fb-4675-9730-02f29732bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset has unnecessary columns named 'Unnamed: 2', 'Unnamed: 3', and 'Unnamed: 4'.\n",
    "# Drop these columns as they seem to contain mostly NaN values.\n",
    "df_cleaned = df[['v1', 'v2']]\n",
    "\n",
    "# Rename columns for better readability\n",
    "df_cleaned.columns = ['Label', 'Text']\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01bc0d94-2cc4-4a66-a3da-a389c401b019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many 'ham' and 'spam' messages we have in the dataset\n",
    "df_cleaned['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22e4bc1-be67-44cb-904e-9e246df5daaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               Text\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a few examples of spam and ham messages\n",
    "spam_messages = df_cleaned[df_cleaned['Label'] == 'spam']\n",
    "ham_messages = df_cleaned[df_cleaned['Label'] == 'ham']\n",
    "\n",
    "# Display first 5 spam messages\n",
    "spam_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9c9aac-cfbf-4ccb-b14f-2a9dfcfa2506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "6   ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 ham messages\n",
    "ham_messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084740b6-b573-413a-8da7-60ed0bc4cad4",
   "metadata": {},
   "source": [
    "<b> SECTION 2: next step is pre-processing of the text data and preparing it for training </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af36897-1980-46c6-833a-f198b79f97a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in  a wkly comp to win fa cup final...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function cleans the text by removing punctuation, lowercasing the text, \n",
    "    and removing non-alphabetic characters.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Input text string.\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned text.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove any non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'Text' column\n",
    "df_cleaned['Cleaned_Text'] = df_cleaned['Text'].apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eabf736-515e-4f85-a4c2-95949b1e5be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding: {'ham': 0, 'spam': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  Label_Encoded\n",
       "0   ham              0\n",
       "1   ham              0\n",
       "2  spam              1\n",
       "3   ham              0\n",
       "4   ham              0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Convert labels ('ham' and 'spam') into binary values\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder and transform labels\n",
    "df_cleaned['Label_Encoded'] = label_encoder.fit_transform(df_cleaned['Label'])\n",
    "\n",
    "# Display the mapping of labels \n",
    "print(f\"Label Encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "\n",
    "# Check the dataset after encoding the labels\n",
    "df_cleaned[['Label', 'Label_Encoded']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5fd405d-070f-49ef-b513-a10bf1da63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (4457, 2)\n",
      "Test Data Shape: (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into training and test sets\n",
    "train_data, test_data = train_test_split(df_cleaned[['Cleaned_Text', 'Label_Encoded']], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to binary (0 or 1)\n",
    "train_data['Label_Encoded'] = train_data['Label_Encoded'].astype(int)\n",
    "test_data['Label_Encoded'] = test_data['Label_Encoded'].astype(int)\n",
    "\n",
    "\n",
    "# Check the shape of the training and test data\n",
    "print(f\"Training Data Shape: {train_data.shape}\")\n",
    "print(f\"Test Data Shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad3b1a3-5ee5-45a4-9466-a067dcfad24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Label_Encoded</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>no im in the same boat still here at my moms c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[no, im, in, the, same, boat, still, here, at,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>bank of granite issues strongbuy explosive pic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bank, of, granite, issues, strongbuy, explosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>they r giving a second chance to rahul dengra</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, r, giving, a, second, chance, to, rahul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>o i played smash bros  ltgt  religiously</td>\n",
       "      <td>0</td>\n",
       "      <td>[o, i, played, smash, bros, ltgt, religiously]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>private your  account statement for  shows  un...</td>\n",
       "      <td>1</td>\n",
       "      <td>[private, your, account, statement, for, shows...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Cleaned_Text  Label_Encoded  \\\n",
       "1978  no im in the same boat still here at my moms c...              0   \n",
       "3989  bank of granite issues strongbuy explosive pic...              1   \n",
       "3935      they r giving a second chance to rahul dengra              0   \n",
       "4078           o i played smash bros  ltgt  religiously              0   \n",
       "4086  private your  account statement for  shows  un...              1   \n",
       "\n",
       "                                         Tokenized_Text  \n",
       "1978  [no, im, in, the, same, boat, still, here, at,...  \n",
       "3989  [bank, of, granite, issues, strongbuy, explosi...  \n",
       "3935  [they, r, giving, a, second, chance, to, rahul...  \n",
       "4078     [o, i, played, smash, bros, ltgt, religiously]  \n",
       "4086  [private, your, account, statement, for, shows...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization using NLTK\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function tokenizes the input text into a list of words (tokens) using nltk's word_tokenize.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Input text string.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of tokens (words).\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "# Apply the tokenization function to both training and test data\n",
    "train_data['Tokenized_Text'] = train_data['Cleaned_Text'].apply(tokenize)\n",
    "test_data['Tokenized_Text'] = test_data['Cleaned_Text'].apply(tokenize)\n",
    "\n",
    "# Display the tokenized text\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c479d45c-0eb4-4f62-9f85-f5210709fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Cleaned_Text', 'Label_Encoded', 'Tokenized_Text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# what columns do we have now?\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7ffbf-00a8-4ab8-8b34-27582b3a673b",
   "metadata": {},
   "source": [
    "<b> SECTION 3: define a simple feedforward network </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8b62d6f-880d-4402-9f3a-486f4a4e155c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocabulary is: 7546\n",
      "FeedForwardNNWithEmbedding(\n",
      "  (embedding): Embedding(7546, 10)\n",
      "  (fc1): Linear(in_features=10, out_features=60, bias=True)\n",
      "  (fc2): Linear(in_features=60, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all tokens in the dataset\n",
    "all_tokens = [token for tokens in train_data['Tokenized_Text'] for token in tokens]\n",
    "\n",
    "# Build the vocabulary (unique words)\n",
    "vocab = Counter(all_tokens)\n",
    "vocab_size = len(vocab) + 1\n",
    "print(f\"length of vocabulary is: {vocab_size}\")\n",
    "\n",
    "\n",
    "class FeedForwardNNWithEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initializes the feedforward neural network with an embedding layer.\n",
    "\n",
    "        Args:\n",
    "        vocab_size (int): The size of the vocabulary (number of unique tokens).\n",
    "        embedding_dim (int): The size of the word embedding vectors.\n",
    "        hidden_size (int): The size of the hidden layer.\n",
    "        output_size (int): The size of the output layer (for binary classification, this is 1).\n",
    "        \"\"\"\n",
    "        super(FeedForwardNNWithEmbedding, self).__init__()\n",
    "        \n",
    "        # Embedding layer to convert word indices into dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Define the layers of the network\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_size)  # Fully connected layer (input from embedding layer)\n",
    "        self.sigmoid = nn.functional.sigmoid  # Activation function. Try ReLu?\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "        \n",
    "        Args:\n",
    "        x (torch.Tensor): The input tensor containing word indices.\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: The output prediction tensor.\n",
    "        \"\"\"\n",
    "        # Pass the input through the embedding layer\n",
    "        x = self.embedding(x)\n",
    "        # Average the embeddings (since input is a sequence of words)\n",
    "        x = x.mean(dim=1)  # Reduce the sequence dimension to get a single vector for each example\n",
    "        # Pass the averaged embedding through the first fully connected layer\n",
    "        out = self.fc1(x)\n",
    "        # Apply activation\n",
    "        out = self.sigmoid(out)\n",
    "        # Pass the result through the output layer\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Step 3: Set hyperparameters. Play around with them?\n",
    "embedding_dim = 10  # The size of the word embedding vectors\n",
    "hidden_size = 60   # Number of hidden units in the hidden layer\n",
    "output_size = 1     # Output size for binary classification (1 output neuron)\n",
    "\n",
    "# Create the model\n",
    "model = FeedForwardNNWithEmbedding(vocab_size, embedding_dim, hidden_size, output_size)\n",
    "\n",
    "# Display the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5fc0fed-6432-4f52-be82-a088c2ae14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with logits (since output is raw score)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)  # Adam optimizer with a learning rate of 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef42fd-bc45-49de-a9fd-d00595ddf9ba",
   "metadata": {},
   "source": [
    "<b> SECTION 4: Create DataLoader object </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7daacba-7720-45f1-95b6-498b9e21c9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Label_Encoded</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>no im in the same boat still here at my moms c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[no, im, in, the, same, boat, still, here, at,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>bank of granite issues strongbuy explosive pic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bank, of, granite, issues, strongbuy, explosi...</td>\n",
       "      <td>[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>they r giving a second chance to rahul dengra</td>\n",
       "      <td>0</td>\n",
       "      <td>[they, r, giving, a, second, chance, to, rahul...</td>\n",
       "      <td>[37, 38, 39, 35, 40, 41, 42, 43, 44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>o i played smash bros  ltgt  religiously</td>\n",
       "      <td>0</td>\n",
       "      <td>[o, i, played, smash, bros, ltgt, religiously]</td>\n",
       "      <td>[45, 46, 47, 48, 49, 50, 51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>private your  account statement for  shows  un...</td>\n",
       "      <td>1</td>\n",
       "      <td>[private, your, account, statement, for, shows...</td>\n",
       "      <td>[52, 53, 54, 55, 25, 56, 57, 58, 46, 59, 60, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Cleaned_Text  Label_Encoded  \\\n",
       "1978  no im in the same boat still here at my moms c...              0   \n",
       "3989  bank of granite issues strongbuy explosive pic...              1   \n",
       "3935      they r giving a second chance to rahul dengra              0   \n",
       "4078           o i played smash bros  ltgt  religiously              0   \n",
       "4086  private your  account statement for  shows  un...              1   \n",
       "\n",
       "                                         Tokenized_Text  \\\n",
       "1978  [no, im, in, the, same, boat, still, here, at,...   \n",
       "3989  [bank, of, granite, issues, strongbuy, explosi...   \n",
       "3935  [they, r, giving, a, second, chance, to, rahul...   \n",
       "4078     [o, i, played, smash, bros, ltgt, religiously]   \n",
       "4086  [private, your, account, statement, for, shows...   \n",
       "\n",
       "                                                Indices  \n",
       "1978  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "3989  [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 2...  \n",
       "3935               [37, 38, 39, 35, 40, 41, 42, 43, 44]  \n",
       "4078                       [45, 46, 47, 48, 49, 50, 51]  \n",
       "4086  [52, 53, 54, 55, 25, 56, 57, 58, 46, 59, 60, 6...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add <UNK> token to the vocabulary\n",
    "vocab['<UNK>'] = len(vocab)  # Assign a unique index to <UNK> token\n",
    "\n",
    "# Step 2: Create a mapping from words to indices\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Convert tokenized text into lists of indices\n",
    "def tokens_to_indices(tokenized_text):\n",
    "    \"\"\"\n",
    "    Convert tokenized text into indices based on the vocabulary.\n",
    "\n",
    "    Args:\n",
    "    tokenized_text (list of str): Tokenized text (list of words).\n",
    "    \n",
    "    Returns:\n",
    "    list: List of word indices.\n",
    "    \"\"\"\n",
    "    return [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokenized_text]  # Use <UNK> for unknown words\n",
    "\n",
    "# Apply the conversion to the tokenized text in both train and test datasets\n",
    "train_data['Indices'] = train_data['Tokenized_Text'].apply(tokens_to_indices)\n",
    "test_data['Indices'] = test_data['Tokenized_Text'].apply(tokens_to_indices)\n",
    "\n",
    "# Display the first few rows to see the converted indices\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c75b3cdb-c319-4861-90d2-35809f42e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with tokenized text (converted to indices) and labels.\n",
    "        \n",
    "        Args:\n",
    "        texts (list of lists): List of tokenized text converted to indices.\n",
    "        labels (list of int): List of encoded labels (0 for ham, 1 for spam).\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]  # Already padded indices\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(text, dtype=torch.long), torch.tensor(label, dtype=torch.float)  # Label should be float for BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "# Create datasets for training and testing\n",
    "train_dataset = SpamDataset(train_data['Indices'].tolist(), train_data['Label_Encoded'].tolist())\n",
    "test_dataset = SpamDataset(test_data['Indices'].tolist(), test_data['Label_Encoded'].tolist())\n",
    "\n",
    "# Create DataLoader objects for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deeb1b32-daf3-406a-9ad9-a458c41a0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    # Pad the sequences to have the same length\n",
    "    texts = [torch.tensor(text, dtype=torch.long) for text in texts]\n",
    "    texts_padded = rnn_utils.pad_sequence(texts, batch_first=True, padding_value=0)  # Padding value 0 for <PAD>\n",
    "    \n",
    "    # Convert labels to a tensor\n",
    "    labels = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    # Move the data to the appropriate device (GPU if available)\n",
    "    texts_padded = texts_padded.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    return texts_padded, labels\n",
    "\n",
    "# Step 2: Update the DataLoader to use the custom collate function\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29276e-2145-4ebe-aca3-2418dbadac5e",
   "metadata": {},
   "source": [
    "<b> SECTION 5: creating the training loop and training the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c005f6ff-4854-4a92-8ac9-ce410cea1552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1829\n",
      "Test Accuracy after Epoch 1: 0.9686\n",
      "Epoch [2/10], Loss: 0.0339\n",
      "Test Accuracy after Epoch 2: 0.9740\n",
      "Epoch [3/10], Loss: 0.0171\n",
      "Test Accuracy after Epoch 3: 0.9785\n",
      "Epoch [4/10], Loss: 0.0111\n",
      "Test Accuracy after Epoch 4: 0.9713\n",
      "Epoch [5/10], Loss: 0.0058\n",
      "Test Accuracy after Epoch 5: 0.9668\n",
      "Epoch [6/10], Loss: 0.0024\n",
      "Test Accuracy after Epoch 6: 0.9758\n",
      "Epoch [7/10], Loss: 0.0172\n",
      "Test Accuracy after Epoch 7: 0.9695\n",
      "Epoch [8/10], Loss: 0.0047\n",
      "Test Accuracy after Epoch 8: 0.9758\n",
      "Epoch [9/10], Loss: 0.0034\n",
      "Test Accuracy after Epoch 9: 0.9731\n",
      "Epoch [10/10], Loss: 0.0017\n",
      "Test Accuracy after Epoch 10: 0.9776\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "#  Define the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Loop over batches of training data\n",
    "    for texts, labels in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute the model output\n",
    "        outputs = model(texts)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward pass: compute the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss for monitoring\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the loss after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Step 3: Evaluate the model on the test data\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for texts, labels in test_loader:\n",
    "            outputs = model(texts)\n",
    "            predicted = torch.sigmoid(outputs).squeeze() > 0.5  # Convert logits to binary output\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy after Epoch {epoch+1}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec342ed8-799f-441e-9e0d-3c944aa6d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       965\n",
      "        spam       0.94      0.89      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect predictions and true labels for the entire test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for texts, labels in test_loader:\n",
    "        outputs = model(texts)\n",
    "        predicted = torch.sigmoid(outputs).squeeze() > 0.5  # Convert logits to binary output\n",
    "        all_preds.extend(predicted.cpu().numpy())  # Move to CPU and convert to numpy array\n",
    "        all_labels.extend(labels.cpu().numpy())  # Move to CPU and convert to numpy array\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=['ham', 'spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643f98d-7e26-4bf5-a832-99b19ef8c826",
   "metadata": {},
   "source": [
    "<b> tasks: Do changes in the following: hyperparameters, embedding, activation function, optimizer, dataset, multiclass dataset, etc</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3d1aa-325f-41f9-b92a-5ffd2db805e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
